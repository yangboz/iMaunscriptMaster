1.customize your local LLM by ollama , for example ollama pull smartkit/manuscriptMaster
2.using langchain customize prompt query your ollama model by fastapi
3.fastapi wrapping previous functions as a api
