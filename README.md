customize your local LLM by ollama , for example ollama pull smartkit/manuscriptMaster
using langchain customize prompt query your ollama model by fastapi
fastapi wrapping previous functions as a api
